From 690e3bb65de0dc747fdc2418ff2f38fcd696fcea Mon Sep 17 00:00:00 2001
From: Ananth Krishna R <ananth.krishna.r@intel.com>
Date: Wed, 11 Mar 2015 04:02:24 +0530
Subject: [PATCH] [CPUFREQ]:HotFix logic error in patch for AKP-1178 with
 commit: If636526d82e37d4dc82064f98e091eca49a30bab, which enable feature:

Improve load representation in CPUFreq governor:
cpufreq_interactive.c iowait was consider as system load dynamically
according to IRQ+SIRQ, which reveals the interaction between IO and CPU,
higher IRQ_SIRQ, more SW overhead. thus need more processor power.

Signed-off-by: Wang Zongtao <zongtao.wang@intel.com>
Signed-off-by: Ananth Krishna R <ananth.krishna.r@intel.com>

Change-Id: Ieeb0c316208bcaa8a91873199105c6528ec20654
---
 Documentation/cpu-freq/governors.txt  |    9 +
 drivers/cpufreq/cpufreq_interactive.c |  217 ++++++++++++++++++++++++++++++++--
 2 files changed, 217 insertions(+), 9 deletions(-)

Index: b/Documentation/cpu-freq/governors.txt
===================================================================
--- a/Documentation/cpu-freq/governors.txt	2016-01-25 15:46:56.766437337 -0800
+++ b/Documentation/cpu-freq/governors.txt	2016-01-25 15:46:56.850438079 -0800
@@ -302,6 +302,15 @@
 on a write to boostpulse, before allowing speed to drop according to
 load as usual.  Default is 80000 uS.
 
+irq_load_threshold: when time spent to deal irq handling,including
+both hard and soft irq, reach this ratio, io_is_busy logic will be switched on
+whether or not that parameter is set to 1. this option was added to
+better perform workload which is both CPU and io intensive. set 100 to
+parameter this will disable this feature.
+
+iowait_load_threshold: works with parameter:irq_load_threshold,
+when CPU spent time on iowait reaching this threshold and irq_load_threshold
+was meet, CPU will scale to max available freqnecy.
 
 3. The Governor Interface in the CPUfreq Core
 =============================================
Index: b/drivers/cpufreq/cpufreq_interactive.c
===================================================================
--- a/drivers/cpufreq/cpufreq_interactive.c	2016-01-25 15:46:56.822437832 -0800
+++ b/drivers/cpufreq/cpufreq_interactive.c	2016-01-25 15:49:16.743677337 -0800
@@ -39,11 +39,17 @@
 struct cpufreq_interactive_cpuinfo {
 	struct timer_list cpu_timer;
 	struct timer_list cpu_slack_timer;
-	spinlock_t load_lock; /* protects the next 4 fields */
+	spinlock_t load_lock; /* protects the next 8 fields */
 	u64 time_in_idle;
 	u64 time_in_idle_timestamp;
 	u64 cputime_speedadj;
 	u64 cputime_speedadj_timestamp;
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	u64 cputime_irq;
+	u64 time_in_irq;
+	u64 cputime_iowait;
+	u64 time_in_iowait;
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 	struct cpufreq_policy *policy;
 	struct cpufreq_frequency_table *freq_table;
 	spinlock_t target_freq_lock; /*protects target freq */
@@ -123,6 +129,14 @@
 #define DEFAULT_TIMER_SLACK (4 * DEFAULT_TIMER_RATE)
 	int timer_slack_val;
 	bool io_is_busy;
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+#define DEFAULT_IRQ_LOAD_THRESHOLD 5
+#define DEFAULT_IOWAIT_LOAD_THRESHOLD 15
+	bool io_busy;
+	unsigned int io_busy_mask;
+	unsigned int irq_load_threshold_val;
+	unsigned int iowait_load_threshold_val;
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 };
 static int boot_boost;
 static int __init bootboost(char *str)
@@ -135,6 +149,31 @@
 static struct cpufreq_interactive_tunables *common_tunables;
 
 static struct attribute_group *get_sysfs_attr(void);
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+DECLARE_PER_CPU(u64, cpu_hardirq_time);
+DECLARE_PER_CPU(u64, cpu_softirq_time);
+
+static inline u64 irq_time_read(int cpu)
+{
+	/* Return the irq time(us) */
+	u64 irq_time;
+
+	irq_time = per_cpu(cpu_softirq_time, cpu) +
+			per_cpu(cpu_hardirq_time, cpu);
+	do_div(irq_time, 1000);
+	return irq_time;
+}
+
+static inline void update_irq_time(struct cpufreq_interactive_cpuinfo *pcpu)
+{
+	/* Update the time spent in iowait and irq */
+	pcpu->time_in_iowait = get_cpu_iowait_time_us(smp_processor_id(),
+		&pcpu->time_in_idle_timestamp);
+	pcpu->cputime_iowait = 0;
+	pcpu->time_in_irq = irq_time_read(smp_processor_id());
+	pcpu->cputime_irq = 0;
+}
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 
 static void cpufreq_interactive_timer_resched(
 	struct cpufreq_interactive_cpuinfo *pcpu)
@@ -143,12 +182,17 @@
 		pcpu->policy->governor_data;
 	unsigned long expires;
 	unsigned long flags;
+	bool io_is_busy = tunables->io_is_busy;
 
 	spin_lock_irqsave(&pcpu->load_lock, flags);
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	io_is_busy |= tunables->io_busy;
+	update_irq_time(pcpu);
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 	pcpu->time_in_idle =
 		get_cpu_idle_time(smp_processor_id(),
 				  &pcpu->time_in_idle_timestamp,
-				  tunables->io_is_busy);
+				  io_is_busy);
 	pcpu->cputime_speedadj = 0;
 	pcpu->cputime_speedadj_timestamp = pcpu->time_in_idle_timestamp;
 	expires = jiffies + usecs_to_jiffies(tunables->timer_rate);
@@ -174,6 +218,7 @@
 	unsigned long expires = jiffies +
 		usecs_to_jiffies(tunables->timer_rate);
 	unsigned long flags;
+	bool io_is_busy = tunables->io_is_busy;
 
 	pcpu->cpu_timer.expires = expires;
 	add_timer_on(&pcpu->cpu_timer, cpu);
@@ -185,9 +230,13 @@
 	}
 
 	spin_lock_irqsave(&pcpu->load_lock, flags);
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	io_is_busy |= tunables->io_busy;
+	update_irq_time(pcpu);
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 	pcpu->time_in_idle =
 		get_cpu_idle_time(cpu, &pcpu->time_in_idle_timestamp,
-				  tunables->io_is_busy);
+				  io_is_busy);
 	pcpu->cputime_speedadj = 0;
 	pcpu->cputime_speedadj_timestamp = pcpu->time_in_idle_timestamp;
 	spin_unlock_irqrestore(&pcpu->load_lock, flags);
@@ -330,8 +379,26 @@
 	unsigned int delta_idle;
 	unsigned int delta_time;
 	u64 active_time;
+	bool io_is_busy = tunables->io_is_busy;
+
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	u64 now_irq;
+	u64 now_iowait;
+	unsigned int delta_irq;
+	unsigned int delta_iowait;
+
+	io_is_busy |= tunables->io_busy;
+	now_iowait = get_cpu_iowait_time_us(cpu, &now);
+	now_irq = irq_time_read(cpu);
+	delta_irq = (unsigned int)(now_irq - pcpu->time_in_irq);
+	delta_iowait = (unsigned int)(now_iowait - pcpu->time_in_iowait);
+	pcpu->cputime_irq += (u64)delta_irq * pcpu->policy->cur;
+	pcpu->cputime_iowait += (u64)delta_iowait * pcpu->policy->cur;
+	pcpu->time_in_irq = now_irq;
+	pcpu->time_in_iowait = now_iowait;
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 
-	now_idle = get_cpu_idle_time(cpu, &now, tunables->io_is_busy);
+	now_idle = get_cpu_idle_time(cpu, &now, io_is_busy);
 	delta_idle = (unsigned int)(now_idle - pcpu->time_in_idle);
 	delta_time = (unsigned int)(now - pcpu->time_in_idle_timestamp);
 
@@ -362,6 +429,14 @@
 	unsigned int index;
 	unsigned long flags;
 	u64 max_fvtime;
+	unsigned int cur;
+	bool io_boosted = false;
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	u64 cputime_irq;
+	u64 cputime_iowait;
+	unsigned int irq_load;
+	unsigned int iowait_load;
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 
 	if (!down_read_trylock(&pcpu->enable_sem))
 		return;
@@ -372,11 +447,69 @@
 	now = update_load(data);
 	delta_time = (unsigned int)(now - pcpu->cputime_speedadj_timestamp);
 	cputime_speedadj = pcpu->cputime_speedadj;
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	cputime_irq = pcpu->cputime_irq;
+	cputime_iowait = pcpu->cputime_iowait;
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 	spin_unlock_irqrestore(&pcpu->load_lock, flags);
 
 	if (WARN_ON_ONCE(!delta_time))
 		goto rearm;
 
+	cur = pcpu->policy->cur;
+	if (cur == 0)
+		goto rearm;
+
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	/*
+	 * If CPU IRQ load hits the threshold, take IOWAIT into account.
+	 * If all cores' IRQ load less than the threshold, exclude IOWAIT.
+	 */
+
+	/* Calculate the irq and iowait load(%) */
+	cputime_irq = cputime_irq * 100;
+	do_div(cputime_irq, delta_time);
+	irq_load = (unsigned int)cputime_irq / cur;
+	cputime_iowait = cputime_iowait * 100;
+	do_div(cputime_iowait, delta_time);
+	iowait_load = (unsigned int)cputime_iowait / cur;
+
+	if (have_governor_per_policy()) {
+		spin_lock_irqsave(&pcpu->load_lock, flags);
+		if (irq_load >= tunables->irq_load_threshold_val
+			&& iowait_load >= tunables->iowait_load_threshold_val) {
+			io_boosted = true;
+			tunables->io_busy_mask |= 1 << data;
+			tunables->io_busy = true;
+		} else if (irq_load >= tunables->irq_load_threshold_val) {
+			tunables->io_busy_mask |= 1 << data;
+			tunables->io_busy = true;
+		} else {
+			tunables->io_busy_mask &= ~(1 << data);
+		}
+
+		if (!tunables->io_busy_mask)
+			tunables->io_busy = false;
+		spin_unlock_irqrestore(&pcpu->load_lock, flags);
+	} else {
+		if (irq_load >= tunables->irq_load_threshold_val
+			&& iowait_load >= tunables->iowait_load_threshold_val) {
+			io_boosted = true;
+			tunables->io_busy_mask |= 1 << data;
+			tunables->io_busy = true;
+		} else if (irq_load >= tunables->irq_load_threshold_val) {
+			tunables->io_busy_mask |= 1 << data;
+			tunables->io_busy = true;
+		} else {
+			tunables->io_busy_mask &= ~(1 << data);
+		}
+
+		if (!tunables->io_busy_mask)
+			tunables->io_busy = false;
+	}
+
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
+
 	spin_lock_irqsave(&pcpu->target_freq_lock, flags);
 	do_div(cputime_speedadj, delta_time);
 	loadadjfreq = (unsigned int)cputime_speedadj * 100;
@@ -387,7 +520,8 @@
 #endif
 	tunables->boosted = tunables->boost_val || now < tunables->boostpulse_endtime;
 
-	if (cpu_load >= tunables->go_hispeed_load || tunables->boosted) {
+	if (cpu_load >= tunables->go_hispeed_load ||
+			 tunables->boosted || io_boosted) {
 		if (pcpu->policy->cur < tunables->hispeed_freq) {
 			new_freq = tunables->hispeed_freq;
 		} else {
@@ -1099,6 +1233,52 @@
 	return count;
 }
 
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+static ssize_t show_irq_load_threshold(
+	struct cpufreq_interactive_tunables *tunables,
+	char *buf)
+{
+	return sprintf(buf, "%d\n", tunables->irq_load_threshold_val);
+}
+
+static ssize_t store_irq_load_threshold(
+	struct cpufreq_interactive_tunables *tunables,
+	const char *buf, size_t count)
+{
+	int ret;
+	unsigned long val;
+
+	ret = kstrtoul(buf, 0, &val);
+	if (ret < 0)
+		return ret;
+
+	tunables->irq_load_threshold_val = val;
+	return count;
+}
+
+static ssize_t show_iowait_load_threshold(
+	struct cpufreq_interactive_tunables *tunables,
+	char *buf)
+{
+	return sprintf(buf, "%d\n", tunables->iowait_load_threshold_val);
+}
+
+static ssize_t store_iowait_load_threshold(
+	struct cpufreq_interactive_tunables *tunables,
+	const char *buf, size_t count)
+{
+	int ret;
+	unsigned long val;
+
+	ret = kstrtoul(buf, 0, &val);
+	if (ret < 0)
+		return ret;
+
+	tunables->iowait_load_threshold_val = val;
+	return count;
+}
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
+
 /*
  * Create show/store routines
  * - sys: One governor instance for complete SYSTEM
@@ -1149,6 +1329,10 @@
 store_gov_pol_sys(touchboostpulse);
 show_store_gov_pol_sys(touchboostpulse_duration);
 show_store_gov_pol_sys(io_is_busy);
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+show_store_gov_pol_sys(irq_load_threshold);
+show_store_gov_pol_sys(iowait_load_threshold);
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 
 #define gov_sys_attr_rw(_name)						\
 static struct global_attr _name##_gov_sys =				\
@@ -1174,6 +1358,10 @@
 gov_sys_pol_attr_rw(boostpulse_duration);
 gov_sys_pol_attr_rw(touchboostpulse_duration);
 gov_sys_pol_attr_rw(io_is_busy);
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+gov_sys_pol_attr_rw(irq_load_threshold);
+gov_sys_pol_attr_rw(iowait_load_threshold);
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 
 static struct global_attr boostpulse_gov_sys =
 	__ATTR(boostpulse, 0200, NULL, store_boostpulse_gov_sys);
@@ -1203,6 +1391,10 @@
 	&touchboostpulse_gov_sys.attr,
 	&touchboostpulse_duration_gov_sys.attr,
 	&io_is_busy_gov_sys.attr,
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	&irq_load_threshold_gov_sys.attr,
+	&iowait_load_threshold_gov_sys.attr,
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 	NULL,
 };
 
@@ -1227,6 +1419,10 @@
 	&touchboostpulse_gov_pol.attr,
 	&touchboostpulse_duration_gov_pol.attr,
 	&io_is_busy_gov_pol.attr,
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+	&irq_load_threshold_gov_pol.attr,
+	&iowait_load_threshold_gov_pol.attr,
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 	NULL,
 };
 
@@ -1317,6 +1513,13 @@
 		tunables->touchboostpulse_duration_val =
 				DEFAULT_MIN_SAMPLE_TIME;
 		tunables->timer_slack_val = DEFAULT_TIMER_SLACK;
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+		tunables->irq_load_threshold_val =
+				 DEFAULT_IRQ_LOAD_THRESHOLD;
+		tunables->iowait_load_threshold_val =
+				 DEFAULT_IOWAIT_LOAD_THRESHOLD;
+		tunables->io_busy = false;
+#endif /* CONFIG_IRQ_TIME_ACCOUNTING */
 
 		spin_lock_init(&tunables->target_loads_lock);
 		spin_lock_init(&tunables->above_hispeed_delay_lock);
@@ -1324,7 +1527,6 @@
 		policy->governor_data = tunables;
 		if (!have_governor_per_policy()) {
 			common_tunables = tunables;
-			WARN_ON(cpufreq_get_global_kobject());
 		}
 
 		rc = sysfs_create_group(get_governor_parent_kobj(policy),
@@ -1370,9 +1572,6 @@
 			sysfs_remove_group(get_governor_parent_kobj(policy),
 					get_sysfs_attr());
 
-			if (!have_governor_per_policy())
-				cpufreq_put_global_kobject();
-
 			kfree(tunables);
 			common_tunables = NULL;
 		}
