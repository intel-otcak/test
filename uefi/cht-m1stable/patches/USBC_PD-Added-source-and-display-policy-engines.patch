From 2c9c5b516fdbcce4c15d1ad3a2921204073d356c Mon Sep 17 00:00:00 2001
From: Venkataramana Kotakonda <venkataramana.kotakonda@intel.com>
Date: Mon, 29 Jun 2015 12:59:45 +0530
Subject: [PATCH] USBC_PD: Added source and display policy engines.

Source policy engine will be used in provider mode. When an UFP is connected,
src pe responsible for communicating the platform power supply capabilities
and establishing the pd contract with UFP.

Display policy engine will be used for display rendering. Display PE will
negotiate display capabilities with UFP and  establishes either 2X or 4X DP
configuration for display rendering.

Change-Id: I2f9950665a1223a1bc827d8b3a3f30f4c0c3e494
Tracked-On: https://jira01.devtools.intel.com/browse/IMINAN-40628
Signed-off-by: Venkataramana Kotakonda <venkataramana.kotakonda@intel.com>
---
 drivers/usb/typec/pd/Makefile        |   2 +
 drivers/usb/typec/pd/devpolicy_mgr.c |  26 +-
 drivers/usb/typec/pd/devpolicy_mgr.h |   6 +
 drivers/usb/typec/pd/display_pe.c    | 700 +++++++++++++++++++++++++++++++++++
 drivers/usb/typec/pd/policy_engine.c |  21 +-
 drivers/usb/typec/pd/policy_engine.h |  13 +
 drivers/usb/typec/pd/src_port_pe.c   | 329 ++++++++++++++++
 drivers/usb/typec/pd/system_policy.c |   2 +
 drivers/usb/typec/usb_typec_detect.c |   3 +
 include/linux/usb_typec_phy.h        |   7 +
 10 files changed, 1106 insertions(+), 3 deletions(-)
 create mode 100644 drivers/usb/typec/pd/display_pe.c
 create mode 100644 drivers/usb/typec/pd/src_port_pe.c

diff --git a/drivers/usb/typec/pd/Makefile b/drivers/usb/typec/pd/Makefile
index 94414774a432..ac5c24601e3d 100644
--- a/drivers/usb/typec/pd/Makefile
+++ b/drivers/usb/typec/pd/Makefile
@@ -6,6 +6,8 @@ pd_policy-y	:= devpolicy_mgr.o
 pd_policy-y	+= message.o protocol.o
 pd_policy-y	+= policy_engine.o
 pd_policy-y	+= sink_port_pe.o
+pd_policy-y	+= src_port_pe.o
+pd_policy-y	+= display_pe.o
 
 obj-$(CONFIG_USBC_PD_POLICY)		+= pd_policy.o
 obj-$(CONFIG_USBC_SYSTEM_POLICY)	+= system_policy.o
diff --git a/drivers/usb/typec/pd/devpolicy_mgr.c b/drivers/usb/typec/pd/devpolicy_mgr.c
index 891da537c0e7..578833fa3dd3 100644
--- a/drivers/usb/typec/pd/devpolicy_mgr.c
+++ b/drivers/usb/typec/pd/devpolicy_mgr.c
@@ -292,17 +292,29 @@ static void dpm_set_cable_state(struct devpolicy_mgr *dpm,
 				enum cable_type type, enum cable_state state)
 {
 	mutex_lock(&dpm->cable_event_lock);
-	if (type == CABLE_TYPE_PROVIDER) {
+	switch (type) {
+	case CABLE_TYPE_PROVIDER:
 		if (dpm->provider_state != state) {
 			dpm->provider_state = state;
 			typec_notify_cable_state(dpm->phy, "USB-Host",
 							(bool)state);
 		}
-	} else {
+		break;
+	case CABLE_TYPE_CONSUMER:
 		if (dpm->consumer_state != state) {
 			dpm->consumer_state = state;
 			typec_notify_cable_state(dpm->phy, "USB", (bool)state);
 		}
+		break;
+	case CABLE_TYPE_DP_SOURCE:
+		if (dpm->dp_state != state) {
+			dpm->dp_state = state;
+			typec_notify_cable_state(dpm->phy,
+				"USB_TYPEC_DP_SOURCE", (bool)state);
+		}
+		break;
+	default:
+		pr_warn("DPM: Unknown cable type=%d\n", type);
 	}
 	mutex_unlock(&dpm->cable_event_lock);
 	return;
@@ -322,6 +334,15 @@ static int dpm_set_consumer_state(struct devpolicy_mgr *dpm,
 	return 0;
 }
 
+static int dpm_set_display_port_state(struct devpolicy_mgr *dpm,
+					enum cable_state state,
+					enum typec_dp_cable_type type)
+{
+	dpm->phy->dp_type = type;
+	dpm_set_cable_state(dpm, CABLE_TYPE_DP_SOURCE, state);
+	return 0;
+}
+
 static enum cable_state dpm_get_provider_state(struct devpolicy_mgr *dpm)
 {
 	return dpm_get_cable_state(dpm, CABLE_TYPE_PROVIDER);
@@ -484,6 +505,7 @@ static struct dpm_interface interface = {
 	.set_charger_mode = dpm_set_charger_mode,
 	.update_current_lim = dpm_update_current_lim,
 	.get_min_current = dpm_get_min_current,
+	.set_display_port_state = dpm_set_display_port_state,
 };
 
 struct devpolicy_mgr *dpm_register_syspolicy(struct typec_phy *phy,
diff --git a/drivers/usb/typec/pd/devpolicy_mgr.h b/drivers/usb/typec/pd/devpolicy_mgr.h
index 9c41d2798882..c053d542f6ac 100644
--- a/drivers/usb/typec/pd/devpolicy_mgr.h
+++ b/drivers/usb/typec/pd/devpolicy_mgr.h
@@ -2,6 +2,7 @@
 #define __PD_DEVMGR_POLICY_H__
 
 #include <linux/extcon.h>
+#include <linux/usb_typec_phy.h>
 
 #define CABLE_CONSUMER	"USB_TYPEC_UFP"
 #define CABLE_PROVIDER	"USB_TYPEC_DFP"
@@ -44,6 +45,7 @@ enum psy_type {
 /* host mode: max of 5V, 1A */
 #define VBUS_5V		5000
 #define IBUS_1A		1000
+#define IBUS_0P5A	500
 
 /* device mode: max of 12, 3A */
 #define VIN_12V		12000
@@ -137,6 +139,9 @@ struct dpm_interface {
 					int ilim);
 	int (*get_min_current)(struct devpolicy_mgr *dpm,
 					int *ma);
+	int (*set_display_port_state)(struct devpolicy_mgr *dpm,
+					enum cable_state state,
+					enum typec_dp_cable_type type);
 };
 
 struct devpolicy_mgr {
@@ -154,6 +159,7 @@ struct devpolicy_mgr {
 	spinlock_t cable_event_queue_lock;
 	enum cable_state consumer_state;    /* cosumer cable state */
 	enum cable_state provider_state;    /* provider cable state */
+	enum cable_state dp_state;    /* display cable state */
 	enum cable_type prev_cable_evt;
 	enum pwr_role prole;
 	enum data_role drole;
diff --git a/drivers/usb/typec/pd/display_pe.c b/drivers/usb/typec/pd/display_pe.c
new file mode 100644
index 000000000000..e7423bc97ecf
--- /dev/null
+++ b/drivers/usb/typec/pd/display_pe.c
@@ -0,0 +1,700 @@
+/*
+ * src_port_pe.c: Intel USB Power Delivery Source Port Policy Engine
+ *
+ * Copyright (C) 2015 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Seee the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Venkataramana Kotakonda <venkataramana.kotakonda@intel.com>
+ */
+
+#include <linux/slab.h>
+#include <linux/export.h>
+#include "message.h"
+#include "policy_engine.h"
+
+#define LOG_TAG "disp_pe"
+#define log_info(format, ...) \
+	pr_info(LOG_TAG":%s:"format, __func__, ##__VA_ARGS__)
+#define log_dbg(format, ...) \
+	pr_debug(LOG_TAG":%s:"format, __func__, ##__VA_ARGS__)
+#define log_err(format, ...) \
+	pr_err(LOG_TAG":%s:"format, __func__, ##__VA_ARGS__)
+#define log_warn(format, ...) \
+	pr_warn(LOG_TAG":%s:"format, __func__, ##__VA_ARGS__)
+
+#define MAX_CMD_RETRY	10
+#define CMD_NORESPONCE_TIME	1 /* 1 Sec */
+
+#define PD_SID          0xff00
+#define VESA_SVID       0xff01
+#define STRUCTURED_VDM	1
+
+/* Display port pin assignments */
+#define DISP_PORT_PIN_ASSIGN_A	(1 << 0)
+#define DISP_PORT_PIN_ASSIGN_B	(1 << 1)
+#define DISP_PORT_PIN_ASSIGN_C	(1 << 2)
+#define DISP_PORT_PIN_ASSIGN_D	(1 << 3)
+#define DISP_PORT_PIN_ASSIGN_E	(1 << 4)
+#define DISP_PORT_PIN_ASSIGN_F	(1 << 5)
+
+/* Display configuration */
+#define DISP_CONFIG_USB		0
+#define DISP_CONFIG_UFPU_AS_DFP_D	1
+#define DISP_CONFIG_UFPU_AS_UFP_D	2
+#define DISP_CONFIG_RESERVED		3
+
+/* Display port signaling for transport */
+#define DISP_PORT_SIGNAL_UNSPEC		0
+#define DISP_PORT_SIGNAL_DP_1P3		1
+#define DISP_PORT_SIGNAL_GEN2		2
+
+
+struct disp_port_pe {
+	struct mutex pe_lock;
+	struct policy p;
+	int state;
+	struct delayed_work start_comm;
+	int cmd_retry;
+	int dp_mode;
+	bool hpd_state;
+};
+
+/* Source policy engine states */
+enum disp_pe_state {
+	DISP_PE_STATE_UNKNOWN = -1,
+	DISP_PE_STATE_NONE,
+	DISP_PE_STATE_DI_SENT,
+	DISP_PE_STATE_DI_GCRC,
+	DISP_PE_STATE_SVID_SENT,
+	DISP_PE_STATE_SVID_GCRC,
+	DISP_PE_STATE_DMODE_SENT,
+	DISP_PE_STATE_DMODE_GCRC,
+	DISP_PE_STATE_EMODE_SENT,
+	DISP_PE_STATE_EMODE_GCRC,
+	DISP_PE_STATE_EMODE_SUCCESS,
+	DISP_PE_STATE_DISPLAY_CONFIGURED,
+	DISP_PE_STATE_ALT_MODE_FAIL,
+};
+
+static void disp_pe_reset_policy_engine(struct disp_port_pe *disp_pe)
+{
+	disp_pe->state = DISP_PE_STATE_NONE;
+}
+
+static void disp_pe_do_protocol_reset(struct disp_port_pe *disp_pe)
+{
+	policy_send_packet(&disp_pe->p, NULL, 0, PD_CMD_PROTOCOL_RESET,
+				PE_EVT_SEND_PROTOCOL_RESET);
+}
+
+static int
+disp_pe_handle_gcrc(struct disp_port_pe *disp_pe, struct pd_packet *pkt)
+{
+	int ret = 0;
+
+	mutex_lock(&disp_pe->pe_lock);
+	switch (disp_pe->state) {
+	case DISP_PE_STATE_DI_SENT:
+		disp_pe->state = DISP_PE_STATE_DI_GCRC;
+		log_dbg("DISP_PE_STATE_DI_SENT -> DISP_PE_STATE_DI_GCRC\n");
+		break;
+	case DISP_PE_STATE_SVID_SENT:
+		disp_pe->state = DISP_PE_STATE_SVID_GCRC;
+		log_dbg("DISP_PE_STATE_SVID_SENT -> DISP_PE_STATE_SVID_GCRC\n");
+		break;
+	case DISP_PE_STATE_DMODE_SENT:
+		disp_pe->state = DISP_PE_STATE_DMODE_GCRC;
+		log_dbg("DISP_PE_STATE_DMODE_SENT -> DISP_PE_STATE_DMODE_GCRC\n");
+		break;
+	case DISP_PE_STATE_EMODE_SENT:
+		disp_pe->state = DISP_PE_STATE_EMODE_GCRC;
+		log_dbg("DISP_PE_STATE_EMODE_SENT -> DISP_PE_STATE_EMODE_GCRC\n");
+		break;
+	case DISP_PE_STATE_EMODE_SUCCESS:
+		log_dbg("State ->DISP_PE_STATE_EMODE_SUCCESS\n");
+		break;
+	default:
+		ret = -EINVAL;
+		log_dbg("GCRC received in wrong state=%d\n", disp_pe->state);
+	}
+	mutex_unlock(&disp_pe->pe_lock);
+	return ret;
+}
+
+
+static void disp_pe_prepare_vdm_header(struct pd_packet *pkt, enum vdm_cmd cmd,
+					int svid, int obj_pos)
+{
+	struct vdm_header *v_hdr = (struct vdm_header *) &pkt->data_obj[0];
+
+	memset(pkt, 0, sizeof(struct pd_packet));
+	v_hdr->cmd = cmd;
+	v_hdr->cmd_type = INITIATOR;
+	v_hdr->obj_pos = obj_pos;
+	v_hdr->str_vdm_version = 0x0; /* 0 = version 1.0 */
+	v_hdr->vdm_type = STRUCTURED_VDM; /* Structured VDM */
+	v_hdr->svid = svid;
+
+}
+
+static int disp_pe_send_discover_identity(struct disp_port_pe *disp_pe)
+{
+	struct pd_packet pkt;
+	int ret;
+
+	disp_pe_prepare_vdm_header(&pkt, DISCOVER_IDENTITY,
+						PD_SID, 0);
+	ret = policy_send_packet(&disp_pe->p, &pkt.data_obj[0], 4,
+				PD_DATA_MSG_VENDOR_DEF, PE_EVT_SEND_VDM);
+
+	return ret;
+}
+
+static int disp_pe_send_discover_svid(struct disp_port_pe *disp_pe)
+{
+	struct pd_packet pkt;
+	int ret;
+
+	disp_pe_prepare_vdm_header(&pkt, DISCOVER_SVID,
+						PD_SID, 0);
+	ret = policy_send_packet(&disp_pe->p, &pkt.data_obj[0], 4,
+				PD_DATA_MSG_VENDOR_DEF, PE_EVT_SEND_VDM);
+
+	return ret;
+}
+
+static int disp_pe_send_discover_mode(struct disp_port_pe *disp_pe, int svid)
+{
+	struct pd_packet pkt;
+	int ret;
+
+	disp_pe_prepare_vdm_header(&pkt, DISCOVER_MODE,
+						svid, 0);
+	ret = policy_send_packet(&disp_pe->p, &pkt.data_obj[0], 4,
+				PD_DATA_MSG_VENDOR_DEF, PE_EVT_SEND_VDM);
+
+	return ret;
+}
+
+static int disp_pe_send_enter_mode(struct disp_port_pe *disp_pe, int index)
+{
+	struct pd_packet pkt;
+	int ret;
+
+	disp_pe_prepare_vdm_header(&pkt, ENTER_MODE,
+						VESA_SVID, index);
+	ret = policy_send_packet(&disp_pe->p, &pkt.data_obj[0], 4,
+				PD_DATA_MSG_VENDOR_DEF, PE_EVT_SEND_VDM);
+
+	return ret;
+}
+
+static int disp_pe_send_display_configure(struct disp_port_pe *disp_pe)
+{
+	struct pd_packet pkt;
+	struct disp_config *dconf;
+	int ret;
+
+	disp_pe_prepare_vdm_header(&pkt, DP_CONFIGURE,
+						VESA_SVID, 0);
+	dconf = (struct disp_config *)&pkt.data_obj[1];
+	dconf->conf_sel = DISP_CONFIG_UFPU_AS_UFP_D;
+	dconf->trans_sig = DISP_PORT_SIGNAL_DP_1P3;
+	dconf->ufp_pin = DISP_PORT_PIN_ASSIGN_E;
+
+	ret = policy_send_packet(&disp_pe->p, &pkt.data_obj[0], 8,
+				PD_DATA_MSG_VENDOR_DEF, PE_EVT_SEND_VDM);
+
+	return ret;
+}
+
+static int disp_pe_handle_discover_identity(struct disp_port_pe *disp_pe,
+							struct pd_packet *pkt)
+{
+	struct vdm_header *vdm_hdr = (struct vdm_header *)&pkt->data_obj[0];
+
+	switch (vdm_hdr->cmd_type) {
+	case INITIATOR:
+		log_warn("UFP alternate mode not supported\n");
+		break;
+	case REP_ACK:
+		if ((disp_pe->state != DISP_PE_STATE_DI_SENT)
+			&& (disp_pe->state != DISP_PE_STATE_DI_GCRC)) {
+			log_warn("DI RACK received in wrong state,state=%d\n",
+					disp_pe->state);
+			break;
+		}
+		disp_pe_send_discover_svid(disp_pe);
+		mutex_lock(&disp_pe->pe_lock);
+		disp_pe->state = DISP_PE_STATE_SVID_SENT;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_dbg(" State -> DISP_PE_STATE_SVID_SENT\n");
+		break;
+	case REP_NACK:
+		mutex_lock(&disp_pe->pe_lock);
+		cancel_delayed_work(&disp_pe->start_comm);
+		disp_pe->state = DISP_PE_STATE_ALT_MODE_FAIL;
+		disp_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_err("Responder doesn't support alternate mode\n");
+		break;
+	case REP_BUSY:
+		break;
+	}
+	return 0;
+}
+
+
+static int disp_pe_handle_discover_svid(struct disp_port_pe *disp_pe,
+			struct pd_packet *pkt)
+{
+	struct dis_svid_response_pkt *svid_pkt;
+	int num_modes = 0;
+	int i, mode = 0;
+
+	svid_pkt = (struct dis_svid_response_pkt *)pkt;
+
+	switch (svid_pkt->vdm_hdr.cmd_type) {
+	case INITIATOR:
+		log_warn("UFP alternate mode not supported\n");
+		break;
+	case REP_ACK:
+		if ((disp_pe->state != DISP_PE_STATE_SVID_SENT)
+			&& (disp_pe->state != DISP_PE_STATE_SVID_GCRC)) {
+			log_warn("SVID RACK received in wrong state=%d\n",
+					disp_pe->state);
+			break;
+		}
+		/* 2 modes per VDO*/
+		num_modes = (svid_pkt->msg_hdr.num_data_obj - 1) * 2;
+		log_dbg("SVID_ACK-> This Display supports %d modes\n",
+				num_modes);
+		for (i = 0; i < num_modes; i++) {
+			log_dbg("vdo[%d].svid0=0x%x, svid1=0x%x\n",
+				i, svid_pkt->vdo[i].svid0,
+				svid_pkt->vdo[i].svid1);
+			if ((svid_pkt->vdo[i].svid0 == VESA_SVID)
+				|| (svid_pkt->vdo[i].svid1 == VESA_SVID)) {
+				mode = VESA_SVID;
+				break;
+			}
+		}
+		/* Currently we support only VESA */
+		if (mode == VESA_SVID) {
+			log_dbg("This Display supports VESA\n");
+			disp_pe_send_discover_mode(disp_pe, VESA_SVID);
+			mutex_lock(&disp_pe->pe_lock);
+			disp_pe->state = DISP_PE_STATE_DMODE_SENT;
+			mutex_unlock(&disp_pe->pe_lock);
+			log_dbg("State-> DISP_PE_STATE_DMODE_SENT\n");
+			break;
+		} else
+			log_err("This Display doesn't supports VESA\n");
+		/* Stop the display detection process */
+	case REP_NACK:
+		mutex_lock(&disp_pe->pe_lock);
+		cancel_delayed_work(&disp_pe->start_comm);
+		disp_pe->state = DISP_PE_STATE_ALT_MODE_FAIL;
+		disp_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_warn("Responder doesn't support alternate mode\n");
+		break;
+	case REP_BUSY:
+		log_info("Responder BUSY!!. Retry Discover SVID\n");
+		/*TODO: Retry the Discover SVID */
+		break;
+	}
+	return 0;
+}
+
+
+
+static int disp_pe_handle_discover_mode(struct disp_port_pe *disp_pe,
+			struct pd_packet *pkt)
+{
+	struct dis_mode_response_pkt *dmode_pkt;
+	int i;
+	int e_index = 0;
+	int d_index = 0;
+
+	dmode_pkt = (struct dis_mode_response_pkt *)pkt;
+
+	switch (dmode_pkt->vdm_hdr.cmd_type) {
+	case INITIATOR:
+		log_warn("UFP alternate mode not supported\n");
+		break;
+	case REP_ACK:
+		if ((disp_pe->state != DISP_PE_STATE_DMODE_SENT)
+			&& (disp_pe->state != DISP_PE_STATE_DMODE_GCRC)) {
+			log_warn("DiscMode RACK received in wrong state=%d\n",
+					disp_pe->state);
+			break;
+		}
+
+		for (i = 0; i < dmode_pkt->msg_hdr.num_data_obj - 1; i++) {
+			if (dmode_pkt->mode[i].dfp_pin
+				& DISP_PORT_PIN_ASSIGN_E) {
+				/* Mode intex starts from 1 */
+				e_index = i + 1;
+				break;
+			}
+		}
+		for (i = 0; i < dmode_pkt->msg_hdr.num_data_obj - 1; i++) {
+			if (dmode_pkt->mode[i].dfp_pin
+				& DISP_PORT_PIN_ASSIGN_D) {
+				d_index = i + 1;
+				break;
+			}
+		}
+		/* First check for 2X, Mode E */
+		log_dbg("e_index=%d, d_index=%d\n", e_index, d_index);
+		if (e_index) {
+			disp_pe_send_enter_mode(disp_pe, e_index);
+			mutex_lock(&disp_pe->pe_lock);
+			disp_pe->state = DISP_PE_STATE_EMODE_SENT;
+			disp_pe->dp_mode = TYPEC_DP_TYPE_4X;
+			mutex_unlock(&disp_pe->pe_lock);
+			log_dbg("State -> DISP_PE_STATE_EMODE_SENT\n");
+			break;
+		} else if (d_index) {
+			disp_pe_send_enter_mode(disp_pe, d_index);
+			mutex_lock(&disp_pe->pe_lock);
+			disp_pe->state = DISP_PE_STATE_EMODE_SENT;
+			disp_pe->dp_mode = TYPEC_DP_TYPE_2X;
+			mutex_unlock(&disp_pe->pe_lock);
+			log_dbg("State -> DISP_PE_STATE_EMODE_SENT\n");
+			break;
+		}
+		log_warn("This Display doesn't supports neither 2X nor 4X\n");
+		/* Stop the display detection process */
+
+	case REP_NACK:
+		mutex_lock(&disp_pe->pe_lock);
+		cancel_delayed_work(&disp_pe->start_comm);
+		disp_pe->state = DISP_PE_STATE_ALT_MODE_FAIL;
+		disp_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_warn("Responder doesn't support alternate mode\n");
+		break;
+	case REP_BUSY:
+		log_warn("Responder BUSY!!. Retry Discover SVID\n");
+		/*TODO: Retry the Discover SVID */
+		break;
+	}
+	return 0;
+}
+
+
+static int disp_pe_handle_enter_mode(struct disp_port_pe *disp_pe,
+			struct pd_packet *pkt)
+{
+	struct vdm_header *vdm_hdr = (struct vdm_header *)&pkt->data_obj[0];
+
+	switch (vdm_hdr->cmd_type) {
+	case INITIATOR:
+		log_warn("UFP alternate mode not supported\n");
+		break;
+	case REP_ACK:
+		if ((disp_pe->state != DISP_PE_STATE_EMODE_SENT)
+			&& (disp_pe->state != DISP_PE_STATE_EMODE_GCRC)) {
+			log_warn("EnterMode ACK received in wrong state=%d\n",
+					disp_pe->state);
+			break;
+		}
+		mutex_lock(&disp_pe->pe_lock);
+		disp_pe->state = DISP_PE_STATE_EMODE_SUCCESS;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_dbg("State -> DISP_PE_STATE_EMODE_SUCCESS, dp_mode=%d\n",
+				disp_pe->dp_mode);
+		disp_pe_send_display_configure(disp_pe);
+		break;
+	case REP_NACK:
+		log_warn("Display falied to enter dp mode %d\n",
+			disp_pe->dp_mode);
+		cancel_delayed_work(&disp_pe->start_comm);
+		mutex_lock(&disp_pe->pe_lock);
+		disp_pe->state = DISP_PE_STATE_ALT_MODE_FAIL;
+		disp_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&disp_pe->pe_lock);
+	}
+	return 0;
+}
+
+static int disp_pe_handle_display_configure(struct disp_port_pe *disp_pe,
+			struct pd_packet *pkt)
+{
+	struct vdm_header *vdm_hdr = (struct vdm_header *)&pkt->data_obj[0];
+
+	switch (vdm_hdr->cmd_type) {
+	case INITIATOR:
+		log_warn("UFP alternate mode not supported\n");
+		break;
+	case REP_ACK:
+		if (disp_pe->state != DISP_PE_STATE_EMODE_SUCCESS) {
+			log_warn("Config ACK received in wrong state=%d\n",
+					disp_pe->state);
+			break;
+		}
+		mutex_lock(&disp_pe->pe_lock);
+		disp_pe->state = DISP_PE_STATE_DISPLAY_CONFIGURED;
+		disp_pe->p.status = POLICY_STATUS_SUCCESS;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_info("DISP_PE_STATE_DISPLAY_CONFIGURED,dp_mode=%d\n",
+				disp_pe->dp_mode);
+		disp_pe->hpd_state = true;
+		policy_set_dp_state(&disp_pe->p, CABLE_ATTACHED,
+					disp_pe->dp_mode);
+		break;
+	case REP_NACK:
+		log_warn("NAK for display config cmd %d\n", disp_pe->dp_mode);
+		mutex_lock(&disp_pe->pe_lock);
+		cancel_delayed_work(&disp_pe->start_comm);
+		disp_pe->state = DISP_PE_STATE_ALT_MODE_FAIL;
+		disp_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&disp_pe->pe_lock);
+	}
+	return 0;
+}
+
+static int disp_pe_handle_display_attention(struct disp_port_pe *disp_pe,
+		struct pd_packet *pkt)
+{
+	struct dis_port_status *dstat;
+	bool hpd;
+
+	dstat = (struct dis_port_status *) &pkt->data_obj[1];
+	log_info("hpd_status=%d\n", dstat->hpd_state);
+	hpd = dstat->hpd_state;
+
+	/* Some dp cable which doesnt suport status update cmd
+	 * which is expected after EnterMode. Due to this the hpd
+	 * status cannot be known after EnterMode. To fix this by
+	 * default hpd will be triggered after EnterMode.
+	 * So, if previous hpd is true then send diconnect and connect.
+	 */
+	if (hpd && disp_pe->hpd_state) {
+		policy_set_dp_state(&disp_pe->p, CABLE_DETACHED,
+					TYPEC_DP_TYPE_NONE);
+	}
+	disp_pe->hpd_state = hpd;
+	if (hpd)
+		policy_set_dp_state(&disp_pe->p, CABLE_ATTACHED,
+					disp_pe->dp_mode);
+	else
+		policy_set_dp_state(&disp_pe->p, CABLE_DETACHED,
+					TYPEC_DP_TYPE_NONE);
+
+	return 0;
+}
+
+static int disp_pe_handle_vendor_msg(struct disp_port_pe *disp_pe,
+		struct pd_packet *pkt)
+{
+	struct vdm_header *vdm_hdr = (struct vdm_header *)&pkt->data_obj[0];
+	int ret = 0;
+
+	switch (vdm_hdr->cmd) {
+	case DISCOVER_IDENTITY:
+		ret = disp_pe_handle_discover_identity(disp_pe, pkt);
+		break;
+	case DISCOVER_SVID:
+		ret = disp_pe_handle_discover_svid(disp_pe, pkt);
+		break;
+	case DISCOVER_MODE:
+		ret = disp_pe_handle_discover_mode(disp_pe, pkt);
+		break;
+	case ENTER_MODE:
+		ret = disp_pe_handle_enter_mode(disp_pe, pkt);
+		break;
+	case EXIT_MODE:
+		log_dbg("EXIT DP mode request received\n");
+		/* TODO: Handle the exit mode */
+		break;
+	case DP_CONFIGURE:
+		ret = disp_pe_handle_display_configure(disp_pe, pkt);
+		break;
+	/* DP_STATUS_UPDATE and ATTENTION has same status vdo*/
+	case DP_STATUS_UPDATE:
+	case ATTENTION:
+		ret = disp_pe_handle_display_attention(disp_pe, pkt);
+		break;
+	default:
+		ret = -EINVAL;
+		log_err("Not a valid vendor msg to handle\n");
+	}
+	return ret;
+}
+
+
+static int
+disp_pe_rcv_pkt(struct policy *p, struct pd_packet *pkt, enum pe_event evt)
+{
+	struct disp_port_pe *disp_pe = container_of(p,
+					struct disp_port_pe, p);
+	int ret = 0;
+
+	switch (evt) {
+	case PE_EVT_RCVD_GOODCRC:
+		disp_pe_handle_gcrc(disp_pe, pkt);
+		break;
+	case PE_EVT_RCVD_VDM:
+		disp_pe_handle_vendor_msg(disp_pe, pkt);
+		break;
+	default:
+		ret = -EINVAL;
+		log_warn("Not proccessing the event=%d\n", evt);
+	}
+	return ret;
+}
+
+int disp_pe_rcv_cmd(struct policy *p, enum pe_event evt)
+{
+	struct disp_port_pe *disp_pe = container_of(p,
+					struct disp_port_pe, p);
+	int ret = 0;
+
+	log_dbg("Received command, event=%d\n", evt);
+	switch (evt) {
+	case PE_EVT_RCVD_HARD_RESET:
+	case PE_EVT_RCVD_HARD_RESET_COMPLETE:
+		disp_pe_reset_policy_engine(disp_pe);
+	default:
+		ret = EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+
+static void disp_pe_start_comm(struct work_struct *work)
+{
+	struct disp_port_pe *disp_pe = container_of(work,
+					struct disp_port_pe,
+					start_comm.work);
+
+	if ((disp_pe->state == DISP_PE_STATE_ALT_MODE_FAIL)
+		|| (disp_pe->state == DISP_PE_STATE_DISPLAY_CONFIGURED)) {
+		log_dbg("Not required to send DI in this state=%d\n",
+				disp_pe->state);
+		return;
+	}
+
+	if (disp_pe->cmd_retry > 0)
+		disp_pe_do_protocol_reset(disp_pe);
+
+	log_info(" Sending DI\n");
+	mutex_lock(&disp_pe->pe_lock);
+	disp_pe->state = DISP_PE_STATE_DI_SENT;
+	mutex_unlock(&disp_pe->pe_lock);
+	disp_pe_send_discover_identity(disp_pe);
+
+	disp_pe->cmd_retry++;
+	if (disp_pe->cmd_retry < MAX_CMD_RETRY) {
+		log_dbg("Re-scheduling the start_comm after %dSec\n",
+				CMD_NORESPONCE_TIME);
+		/* Retry display identity if dp command sequence
+		 * failed/no responce with in CMD_NORESPONCE_TIME.
+		 */
+		schedule_delayed_work(&disp_pe->start_comm,
+					HZ * CMD_NORESPONCE_TIME);
+	} else {
+		mutex_lock(&disp_pe->pe_lock);
+		disp_pe->state = DISP_PE_STATE_ALT_MODE_FAIL;
+		disp_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&disp_pe->pe_lock);
+		log_warn("Not scheduling srccap as max re-try reached\n");
+	}
+}
+
+static int disp_pe_start_policy_engine(struct policy *p)
+{
+	struct disp_port_pe *disp_pe = container_of(p,
+					struct disp_port_pe, p);
+
+	log_dbg("IN");
+	mutex_lock(&disp_pe->pe_lock);
+	p->state = POLICY_STATE_ONLINE;
+	p->status = POLICY_STATUS_RUNNING;
+	disp_pe->cmd_retry = 0;
+	schedule_delayed_work(&disp_pe->start_comm, 0);
+	mutex_unlock(&disp_pe->pe_lock);
+	return 0;
+}
+
+static int disp_pe_stop_policy_engine(struct policy *p)
+{
+	struct disp_port_pe *disp_pe = container_of(p,
+					struct disp_port_pe, p);
+
+	log_dbg("IN");
+	mutex_lock(&disp_pe->pe_lock);
+	p->state = POLICY_STATE_OFFLINE;
+	p->status = POLICY_STATUS_UNKNOWN;
+	cancel_delayed_work(&disp_pe->start_comm);
+	disp_pe_reset_policy_engine(disp_pe);
+	disp_pe->cmd_retry = 0;
+	disp_pe->dp_mode = TYPEC_DP_TYPE_NONE;
+	if (disp_pe->hpd_state) {
+		policy_set_dp_state(&disp_pe->p, CABLE_DETACHED,
+					TYPEC_DP_TYPE_NONE);
+		disp_pe->hpd_state = false;
+	}
+	mutex_unlock(&disp_pe->pe_lock);
+	return 0;
+}
+
+static void disp_pe_exit(struct policy *p)
+{
+	struct disp_port_pe *disp_pe = container_of(p,
+					struct disp_port_pe, p);
+
+	kfree(disp_pe);
+}
+
+/* Init function to initialize the source policy engine */
+struct policy *disp_pe_init(struct policy_engine *pe)
+{
+	struct disp_port_pe *disp_pe;
+	struct policy *p;
+
+	disp_pe = kzalloc(sizeof(struct disp_port_pe),
+						GFP_KERNEL);
+	if (!disp_pe) {
+		log_err("mem alloc failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	mutex_init(&disp_pe->pe_lock);
+	INIT_DELAYED_WORK(&disp_pe->start_comm, disp_pe_start_comm);
+
+	p = &disp_pe->p;
+	p->type = POLICY_TYPE_DISPLAY;
+	p->state = POLICY_STATE_OFFLINE;
+	p->status = POLICY_STATUS_UNKNOWN;
+	p->pe = pe;
+
+	p->rcv_pkt = disp_pe_rcv_pkt;
+	p->rcv_cmd = disp_pe_rcv_cmd;
+	p->start  = disp_pe_start_policy_engine;
+	p->stop = disp_pe_stop_policy_engine;
+	p->exit = disp_pe_exit;
+
+	log_info("Display pe initialized successfuly");
+	return p;
+}
+EXPORT_SYMBOL_GPL(disp_pe_init);
diff --git a/drivers/usb/typec/pd/policy_engine.c b/drivers/usb/typec/pd/policy_engine.c
index d31004efd369..c39d27cfe67e 100644
--- a/drivers/usb/typec/pd/policy_engine.c
+++ b/drivers/usb/typec/pd/policy_engine.c
@@ -519,7 +519,26 @@ static void pe_init_policy(struct work_struct *work)
 			}
 			list_add_tail(&policy->list, &pe->policy_list);
 			break;
-		/* TODO: Need to add support for display and source pe init */
+		case POLICY_TYPE_SOURCE:
+			policy = src_pe_init(pe);
+			if (IS_ERR_OR_NULL(policy)) {
+				pr_err("%s: unable to init SOURCE_POLICY\n",
+								__func__);
+				continue;
+			}
+			list_add_tail(&policy->list, &pe->policy_list);
+			pr_debug("%s:Successfuly init source pe\n", __func__);
+			break;
+		case POLICY_TYPE_DISPLAY:
+			policy = disp_pe_init(pe);
+			if (IS_ERR_OR_NULL(policy)) {
+				pr_err("%s: unable to init DOSPLAY_POLICY\n",
+								__func__);
+				continue;
+			}
+			list_add_tail(&policy->list, &pe->policy_list);
+			pr_debug("%s:Successfuly init display pe\n", __func__);
+			break;
 		default:
 			/* invalid, dont add it to policy */
 			pr_err("PE: Unknown policy type %d\n",
diff --git a/drivers/usb/typec/pd/policy_engine.h b/drivers/usb/typec/pd/policy_engine.h
index 758e767c4fd9..c37306f28194 100644
--- a/drivers/usb/typec/pd/policy_engine.h
+++ b/drivers/usb/typec/pd/policy_engine.h
@@ -514,6 +514,17 @@ static inline bool policy_get_pd_state(struct policy *p)
 	return -ENOTSUPP;
 }
 
+static inline int policy_set_dp_state(struct policy *p,
+					enum cable_state state,
+					enum typec_dp_cable_type type)
+{
+	if (p && p->pe && p->pe->dpm && p->pe->dpm->interface
+		&& p->pe->dpm->interface->set_display_port_state)
+		return p->pe->dpm->interface->set_display_port_state(p->pe->dpm,
+					state, type);
+	return -ENODEV;
+}
+
 #if defined(CONFIG_USBC_PD) && defined(CONFIG_USBC_PD_POLICY)
 extern int policy_engine_bind_dpm(struct devpolicy_mgr *dpm);
 extern void policy_engine_unbind_dpm(struct devpolicy_mgr *dpm);
@@ -555,6 +566,8 @@ static inline int pe_process_ctrl_msg(struct policy_engine *pe,
 }
 
 extern struct policy *sink_port_policy_init(struct policy_engine *pe);
+struct policy *src_pe_init(struct policy_engine *pe);
+struct policy *disp_pe_init(struct policy_engine *pe);
 extern int dpm_register_pe(struct policy_engine *x, int port);
 extern void dpm_unregister_pe(struct policy_engine *x);
 extern int protocol_bind_pe(struct policy_engine *pe);
diff --git a/drivers/usb/typec/pd/src_port_pe.c b/drivers/usb/typec/pd/src_port_pe.c
new file mode 100644
index 000000000000..c805bb63d313
--- /dev/null
+++ b/drivers/usb/typec/pd/src_port_pe.c
@@ -0,0 +1,329 @@
+/*
+ * src_port_pe.c: Intel USB Power Delivery Source Port Policy Engine
+ *
+ * Copyright (C) 2015 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Seee the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Venkataramana Kotakonda <venkataramana.kotakonda@intel.com>
+ */
+
+#include <linux/slab.h>
+#include <linux/export.h>
+#include "message.h"
+#include "policy_engine.h"
+
+#define LOG_TAG "src_pe"
+#define log_info(format, ...) \
+	pr_info(LOG_TAG":%s:"format"\n", __func__, ##__VA_ARGS__)
+#define log_dbg(format, ...) \
+	pr_debug(LOG_TAG":%s:"format"\n", __func__, ##__VA_ARGS__)
+#define log_err(format, ...) \
+	pr_err(LOG_TAG":%s:"format"\n", __func__, ##__VA_ARGS__)
+
+#define MAX_CMD_RETRY	10
+#define CMD_NORESPONCE_TIME	1 /* 4 Sec */
+
+#define VOLT_TO_SRC_CAP_DATA_OBJ(x)	(x / 50)
+#define CURRENT_TO_SRC_CAP_DATA_OBJ(x)	(x / 10)
+
+struct src_port_pe {
+	struct mutex pe_lock;
+	struct policy p;
+	int state;
+	struct power_cap pcap;
+	struct delayed_work start_comm;
+	int cmd_retry;
+};
+
+/* Source policy engine states */
+enum src_pe_state {
+	SRC_PE_STATE_UNKNOWN = -1,
+	SRC_PE_STATE_NONE,
+	SRC_PE_STATE_SRCCAP_SENT,
+	SRC_PE_STATE_SRCCAP_GCRC,
+	SRC_PE_STATE_ACCEPT_SENT,
+	SRC_PE_STATE_PS_RDY_SENT,
+	SRC_PE_STATE_PD_CONFIGURED,
+	SRC_PE_STATE_PD_FAILED,
+};
+
+static int src_pe_get_default_power_cap(struct src_port_pe *src_pe,
+					struct power_cap *pcap)
+{
+	/* By default 5V/500mA is supported in provider mode */
+	pcap->mv = VBUS_5V;
+	pcap->ma = IBUS_0P5A;
+	return 0;
+}
+
+static int src_pe_get_power_cap(struct src_port_pe *src_pe,
+				struct power_cap *pcap)
+{
+	/* The power capabilities should be read from dev policy manager.
+	 * Currently using default capabilities.
+	 */
+	return src_pe_get_default_power_cap(src_pe, pcap);
+}
+
+static void src_pe_reset_policy_engine(struct src_port_pe *src_pe)
+{
+	src_pe->state = SRC_PE_STATE_NONE;
+	src_pe->pcap.mv = 0;
+	src_pe->pcap.ma = 0;
+}
+
+static int src_pe_send_srccap_cmd(struct src_port_pe *src_pe)
+{
+	int ret;
+	struct pd_fixed_supply_pdo pdo;
+	struct power_cap pcap;
+
+	log_dbg("Sending PD_CMD_HARD_RESET");
+	policy_send_packet(&src_pe->p, NULL, 0, PD_CMD_HARD_RESET,
+				PE_EVT_SEND_HARD_RESET);
+	log_dbg("Sending SrcCap");
+	ret = src_pe_get_power_cap(src_pe, &pcap);
+	if (ret) {
+		log_err("Error in getting power capabilities\n");
+		return ret;
+	}
+	memset(&pdo, 0, sizeof(struct pd_fixed_supply_pdo));
+	pdo.max_cur = CURRENT_TO_SRC_CAP_DATA_OBJ(pcap.ma); /* In 10mA units */
+	pdo.volt = VOLT_TO_SRC_CAP_DATA_OBJ(pcap.mv); /* In 50mV units */
+	pdo.peak_cur = 0; /* No peek current supported */
+	pdo.dual_role_pwr = 1; /* Dual pwr role supported */
+
+	ret = policy_send_packet(&src_pe->p, &pdo, 4,
+				PD_DATA_MSG_SRC_CAP, PE_EVT_SEND_SRC_CAP);
+	return ret;
+}
+
+static inline int src_pe_send_accept_cmd(struct src_port_pe *src_pe)
+{
+
+	return policy_send_packet(&src_pe->p, NULL, 0,
+				PD_CTRL_MSG_ACCEPT, PE_EVT_SEND_ACCEPT);
+}
+
+static inline int src_pe_send_psrdy_cmd(struct src_port_pe *src_pe)
+{
+
+	return policy_send_packet(&src_pe->p, NULL, 0,
+				PD_CTRL_MSG_PS_RDY, PE_EVT_SEND_PS_RDY);
+}
+
+static int
+src_pe_handle_gcrc(struct src_port_pe *src_pe, struct pd_packet *pkt)
+{
+	int ret = 0;
+
+	switch (src_pe->state) {
+	case SRC_PE_STATE_SRCCAP_SENT:
+		mutex_lock(&src_pe->pe_lock);
+		src_pe->state = SRC_PE_STATE_SRCCAP_GCRC;
+		mutex_unlock(&src_pe->pe_lock);
+		log_dbg("SRC_PE_STATE_SRCCAP_SENT -> SRC_PE_STATE_SRCCAP_GCRC");
+		break;
+	case SRC_PE_STATE_ACCEPT_SENT:
+		/* TODO: Enable the 5V  and send PS_DRY */
+		ret = src_pe_send_psrdy_cmd(src_pe);
+		mutex_lock(&src_pe->pe_lock);
+		src_pe->state = SRC_PE_STATE_PS_RDY_SENT;
+		mutex_unlock(&src_pe->pe_lock);
+		log_dbg("SRC_PE_STATE_ACCEPT_SENT -> SRC_PE_STATE_PS_RDY_SENT");
+		break;
+	case SRC_PE_STATE_PS_RDY_SENT:
+		mutex_lock(&src_pe->pe_lock);
+		src_pe->state = SRC_PE_STATE_PD_CONFIGURED;
+		src_pe->p.status = POLICY_STATUS_SUCCESS;
+		mutex_unlock(&src_pe->pe_lock);
+		log_info("SRC_PE_STATE_PS_RDY_SENT -> SRC_PE_STATE_PD_CONFIGURED");
+		pe_notify_policy_status_changed(&src_pe->p,
+				POLICY_TYPE_SOURCE, src_pe->p.status);
+		break;
+	default:
+		ret = -EINVAL;
+		log_info("GCRC received in wrong state=%d\n", src_pe->state);
+	}
+
+	return ret;
+}
+
+static int src_pe_handle_request_cmd(struct src_port_pe *src_pe)
+{
+	if ((src_pe->state == SRC_PE_STATE_SRCCAP_SENT)
+		|| (src_pe->state == SRC_PE_STATE_SRCCAP_GCRC)) {
+		/* Send accept for request */
+		src_pe_send_accept_cmd(src_pe);
+		mutex_lock(&src_pe->pe_lock);
+		src_pe->state = SRC_PE_STATE_ACCEPT_SENT;
+		mutex_unlock(&src_pe->pe_lock);
+		log_dbg(" STATE -> SRC_PE_STATE_ACCEPT_SENT\n");
+		return 0;
+	}
+	log_err(" REQUEST MSG received in wrong state!!!\n");
+	return -EINVAL;
+}
+
+static int
+src_pe_rcv_pkt(struct policy *srcp, struct pd_packet *pkt, enum pe_event evt)
+{
+	struct src_port_pe *src_pe = container_of(srcp,
+					struct src_port_pe, p);
+	int ret = 0;
+
+	switch (evt) {
+	case PE_EVT_RCVD_GOODCRC:
+		ret = src_pe_handle_gcrc(src_pe, pkt);
+		break;
+	case PE_EVT_RCVD_REQUEST:
+		ret = src_pe_handle_request_cmd(src_pe);
+		break;
+	default:
+		ret = -EINVAL;
+		log_info("Not proccessing the event=%d\n", evt);
+	}
+	return ret;
+}
+
+int src_pe_rcv_cmd(struct policy *srcp, enum pe_event evt)
+{
+	struct src_port_pe *src_pe = container_of(srcp,
+					struct src_port_pe, p);
+	int ret = 0;
+
+	switch (evt) {
+	case PE_EVT_RCVD_HARD_RESET:
+	case PE_EVT_RCVD_HARD_RESET_COMPLETE:
+		src_pe_reset_policy_engine(src_pe);
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+static void src_pe_start_comm(struct work_struct *work)
+{
+	struct src_port_pe *src_pe = container_of(work,
+					struct src_port_pe,
+					start_comm.work);
+
+	if ((src_pe->state == SRC_PE_STATE_PD_FAILED)
+		|| (src_pe->state == SRC_PE_STATE_PD_CONFIGURED)
+		|| (src_pe->p.state == POLICY_STATE_OFFLINE)) {
+		log_info("Not required to send srccap in this state=%d\n",
+				src_pe->state);
+		return;
+	}
+
+	src_pe_send_srccap_cmd(src_pe);
+	mutex_lock(&src_pe->pe_lock);
+	src_pe->state = SRC_PE_STATE_SRCCAP_SENT;
+	mutex_unlock(&src_pe->pe_lock);
+
+	src_pe->cmd_retry++;
+	if (src_pe->cmd_retry < MAX_CMD_RETRY) {
+		log_dbg("Re-scheduling the start_comm after %dSec\n",
+				CMD_NORESPONCE_TIME);
+		schedule_delayed_work(&src_pe->start_comm,
+					HZ * CMD_NORESPONCE_TIME);
+	} else {
+		mutex_lock(&src_pe->pe_lock);
+		src_pe->state = SRC_PE_STATE_PD_FAILED;
+		src_pe->p.status = POLICY_STATUS_FAIL;
+		mutex_unlock(&src_pe->pe_lock);
+		log_dbg("Not sending srccap as max re-try reached\n");
+		pe_notify_policy_status_changed(&src_pe->p,
+				POLICY_TYPE_SOURCE, src_pe->p.status);
+	}
+}
+
+static int src_pe_start_policy_engine(struct policy *p)
+{
+	struct src_port_pe *src_pe = container_of(p,
+					struct src_port_pe, p);
+
+	log_info("IN");
+	mutex_lock(&src_pe->pe_lock);
+	p->state = POLICY_STATE_ONLINE;
+	p->status = POLICY_STATUS_RUNNING;
+	policy_set_pd_state(p, true);
+	schedule_delayed_work(&src_pe->start_comm, 0);
+	mutex_unlock(&src_pe->pe_lock);
+	return 0;
+}
+
+static int src_pe_stop_policy_engine(struct policy *p)
+{
+	struct src_port_pe *src_pe = container_of(p,
+					struct src_port_pe, p);
+
+	log_info("IN");
+	mutex_lock(&src_pe->pe_lock);
+	p->state = POLICY_STATE_OFFLINE;
+	p->status = POLICY_STATUS_UNKNOWN;
+	src_pe_reset_policy_engine(src_pe);
+	cancel_delayed_work(&src_pe->start_comm);
+	policy_set_pd_state(p, false);
+	src_pe->cmd_retry = 0;
+	mutex_unlock(&src_pe->pe_lock);
+	return 0;
+}
+
+static void src_pe_exit(struct policy *p)
+{
+	struct src_port_pe *src_pe = container_of(p,
+					struct src_port_pe, p);
+
+	kfree(src_pe);
+}
+
+/* Init function to initialize the source policy engine */
+struct policy *src_pe_init(struct policy_engine *pe)
+{
+	struct src_port_pe *src_pe;
+	struct policy *p;
+
+	src_pe = kzalloc(sizeof(struct src_port_pe),
+						GFP_KERNEL);
+	if (!src_pe) {
+		log_err("mem alloc failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	mutex_init(&src_pe->pe_lock);
+	INIT_DELAYED_WORK(&src_pe->start_comm, src_pe_start_comm);
+
+	p = &src_pe->p;
+	p->type = POLICY_TYPE_SOURCE;
+	p->state = POLICY_STATE_OFFLINE;
+	p->status = POLICY_STATUS_UNKNOWN;
+
+	p->pe = pe;
+	p->rcv_pkt = src_pe_rcv_pkt;
+	p->rcv_cmd = src_pe_rcv_cmd;
+	p->start = src_pe_start_policy_engine;
+	p->stop = src_pe_stop_policy_engine;
+	p->exit = src_pe_exit;
+
+	log_info("Source pe initialized successfuly");
+
+	return p;
+}
+EXPORT_SYMBOL(src_pe_init);
diff --git a/drivers/usb/typec/pd/system_policy.c b/drivers/usb/typec/pd/system_policy.c
index 78284be140e2..04566ff294d5 100644
--- a/drivers/usb/typec/pd/system_policy.c
+++ b/drivers/usb/typec/pd/system_policy.c
@@ -39,6 +39,8 @@ static struct system_policy *spolicy;
 
 static enum policy_type policies[] = {
 	POLICY_TYPE_SINK,
+	POLICY_TYPE_SOURCE,
+	POLICY_TYPE_DISPLAY,
 };
 
 /* FIXME: now supports only one port */
diff --git a/drivers/usb/typec/usb_typec_detect.c b/drivers/usb/typec/usb_typec_detect.c
index 3aada8c12c48..8cc7b94a070c 100644
--- a/drivers/usb/typec/usb_typec_detect.c
+++ b/drivers/usb/typec/usb_typec_detect.c
@@ -50,12 +50,15 @@
 #define TYPEC_CABLE_USB_HOST	"USB-Host"
 #define TYPEC_CABLE_USB_DFP	"USB_TYPEC_DFP"
 #define TYPEC_CABLE_USB_UFP	"USB_TYPEC_UFP"
+#define TYPEC_CABLE_USB_DP_SRC	"USB_TYPEC_DP_SOURCE"
+
 
 static const char *detect_extcon_cable[] = {
 	TYPEC_CABLE_USB,
 	TYPEC_CABLE_USB_HOST,
 	TYPEC_CABLE_USB_UFP,
 	TYPEC_CABLE_USB_DFP,
+	TYPEC_CABLE_USB_DP_SRC,
 	NULL,
 };
 
diff --git a/include/linux/usb_typec_phy.h b/include/linux/usb_typec_phy.h
index 9189351c4fea..740f2753b925 100644
--- a/include/linux/usb_typec_phy.h
+++ b/include/linux/usb_typec_phy.h
@@ -125,6 +125,12 @@ enum typec_cc_vrd {
 	TYPEC_CC_VRD_3000
 };
 
+enum typec_dp_cable_type {
+	TYPEC_DP_TYPE_NONE,
+	TYPEC_DP_TYPE_2X,
+	TYPEC_DP_TYPE_4X,
+};
+
 struct typec_cc_psy {
 	enum typec_cc_level v_rd;
 	enum typec_current cur;
@@ -156,6 +162,7 @@ struct typec_phy {
 	enum typec_type type;
 	enum typec_state state;
 	enum typec_cc_pin valid_cc;
+	enum typec_dp_cable_type dp_type;
 	bool valid_ra;
 	bool support_drp_toggle;
 	bool support_auto_goodcrc;
-- 
1.9.1

