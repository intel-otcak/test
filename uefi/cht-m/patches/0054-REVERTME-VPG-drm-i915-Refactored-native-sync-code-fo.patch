From b6306634e0cbf1378ec5db9140fdb5030c1fa6cc Mon Sep 17 00:00:00 2001
Message-Id: <b6306634e0cbf1378ec5db9140fdb5030c1fa6cc.1413836944.git.chang-joon.lee@intel.com>
In-Reply-To: <5d8aa9994fff43965a6fab8c9a528b8b47a9d624.1413836944.git.chang-joon.lee@intel.com>
References: <5d8aa9994fff43965a6fab8c9a528b8b47a9d624.1413836944.git.chang-joon.lee@intel.com>
From: John Harrison <John.C.Harrison@Intel.com>
Date: Tue, 1 Apr 2014 17:25:21 +0100
Subject: [PATCH 54/71] REVERTME [VPG]: drm/i915: Refactored native sync code
 for better file splits

The native sync code was doing various ring buffer specific things and
execbuffer specific things from intel_sync.c. This does not seem
right. Worse, processing the internals of i915_gem_do_execbuffer()
from somewhere else makes it extremely difficult to implement a GPU
scheduler (which significantly changes the execbuffer code).

This change refactorises the native sync code to put it in more
sensible places. It should have no functional impact.

NB: This is REVERTME because native sync is not accepted upstream.
There is work in progress to implement native sync on top of the linux
dma-sync framework instead.

v2: rebase as per execlists v4.

For: GMIN-2905
Signed-off-by: john.c.harrison@intel.com
Signed-off-by: Arun Siluvery <arun.siluvery@linux.intel.com>
(cherry picked from commit cb4c8074c1909dc6b492de914fc5ff3a9d786a3c)

Change-Id: I8c2653787a1b15b4eb00c1dfa05b5e50ab4d2390
---
 drivers/gpu/drm/i915/i915_gem_execbuffer.c |   73 ++++++++--
 drivers/gpu/drm/i915/intel_lrc.c           |   94 +++++++++++--
 drivers/gpu/drm/i915/intel_ringbuffer.c    |   20 +++
 drivers/gpu/drm/i915/intel_ringbuffer.h    |    2 +
 drivers/gpu/drm/i915/intel_sync.c          |  211 +++-------------------------
 drivers/gpu/drm/i915/intel_sync.h          |   58 +-------
 include/uapi/drm/i915_drm.h                |    2 +-
 7 files changed, 191 insertions(+), 269 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_gem_execbuffer.c b/drivers/gpu/drm/i915/i915_gem_execbuffer.c
index 21d3a1f..315ba37 100644
--- a/drivers/gpu/drm/i915/i915_gem_execbuffer.c
+++ b/drivers/gpu/drm/i915/i915_gem_execbuffer.c
@@ -26,13 +26,14 @@
  *
  */
 
+#include <linux/dma_remapping.h>
+#include <linux/syscalls.h>
 #include <drm/drmP.h>
 #include <drm/i915_drm.h>
 #include "i915_drv.h"
 #include "i915_trace.h"
 #include "intel_sync.h"
 #include "intel_drv.h"
-#include <linux/dma_remapping.h>
 
 #define  __EXEC_OBJECT_HAS_PIN (1<<31)
 #define  __EXEC_OBJECT_HAS_FENCE (1<<30)
@@ -1053,10 +1054,9 @@ i915_gem_ringbuffer_submission(struct drm_device *dev, struct drm_file *file,
 	u32 instp_mask;
 	int i, ret = 0;
 	u32 seqno;
-	int sync_err = 0;
-	void *handle = NULL;
 	void *priv_data = NULL;
 	u32 priv_length = 0;
+	int fd_fence_complete = -1;
 
 	if (args->num_cliprects != 0) {
 		if (INTEL_INFO(dev)->gen <= 4) {
@@ -1122,12 +1122,6 @@ i915_gem_ringbuffer_submission(struct drm_device *dev, struct drm_file *file,
 		goto error;
 
 	seqno = ring->outstanding_lazy_seqno;
-	handle = i915_sync_prepare_request(args, ring, seqno);
-	if (handle && IS_ERR(handle)) {
-		ret = PTR_ERR(handle);
-		if (ret)
-			goto error;
-	}
 
 	ret = i915_gem_execbuffer_move_to_gpu(ring, vmas);
 	if (ret)
@@ -1195,6 +1189,53 @@ i915_gem_ringbuffer_submission(struct drm_device *dev, struct drm_file *file,
 			goto error;
 	}
 
+#ifdef CONFIG_SYNC
+	if (args->flags & I915_EXEC_WAIT_FENCE) {
+		/* Validate the fence wait parameter but don't do the wait until
+		 * a scheduler arrives. Otherwise the entire universe stalls. */
+		int fd_fence_wait = (int) args->rsvd2;
+
+		if (fd_fence_wait < 0) {
+			DRM_ERROR("Wait fence for ring %d has invalid id %d\n",
+				  (int) ring->id, fd_fence_wait);
+		} else {
+			struct sync_fence *fence_wait;
+
+			fence_wait = sync_fence_fdget(fd_fence_wait);
+			if (fence_wait == NULL)
+				DRM_ERROR("Invalid wait fence %d\n",
+					  fd_fence_wait);
+		}
+	}
+#endif
+
+	if (args->flags & I915_EXEC_REQUEST_FENCE) {
+		/* Caller has requested a sync fence.
+		 * User interrupts will be enabled to make sure that
+		 * the timeline is signalled on completion. */
+		ret = i915_sync_create_fence(ring, seqno,
+					     &fd_fence_complete,
+					     args->flags & I915_EXEC_RING_MASK);
+		if (ret) {
+			DRM_ERROR("Fence creation failed for ring %d\n",
+				  ring->id);
+			args->rsvd2 = (__u64) -1;
+			goto error;
+		}
+
+		/* Return the fence through the rsvd2 field */
+		args->rsvd2 = (__u64) fd_fence_complete;
+	}
+
+	/* Flag this seqno as being active on the ring so the watchdog
+	 * code knows where to look if things go wrong. */
+	ret = i915_write_active_seqno(ring, seqno);
+	if (ret) {
+		DRM_DEBUG_DRIVER("Failed to store seqno for %d (%d)\n",
+				 ring->id, ret);
+		goto error;
+	}
+
 	exec_len = args->batch_len;
 	if (cliprects) {
 		/* Non-NULL cliprects only possible for Gen <= 4 */
@@ -1221,7 +1262,10 @@ i915_gem_ringbuffer_submission(struct drm_device *dev, struct drm_file *file,
 			goto error;
 	}
 
-	sync_err = i915_sync_finish_request(handle, args, ring);
+	/* Clear the active seqno again */
+	ret = i915_write_active_seqno(ring, 0);
+	if (ret)
+		goto error;
 
 	trace_i915_gem_ring_dispatch(ring, intel_ring_get_seqno(ring), flags);
 
@@ -1244,11 +1288,14 @@ i915_gem_ringbuffer_submission(struct drm_device *dev, struct drm_file *file,
 	}
 
 error:
-	if (ret || sync_err)
-		i915_sync_cancel_request(handle, args, ring);
-
 	kfree(cliprects);
 	kfree(priv_data);
+
+	if (ret && fd_fence_complete != -1) {
+		sys_close(fd_fence_complete);
+		args->rsvd2 = (__u64) -1;
+	}
+
 	return ret;
 }
 
diff --git a/drivers/gpu/drm/i915/intel_lrc.c b/drivers/gpu/drm/i915/intel_lrc.c
index 6b236ff..7b4c297 100644
--- a/drivers/gpu/drm/i915/intel_lrc.c
+++ b/drivers/gpu/drm/i915/intel_lrc.c
@@ -132,6 +132,7 @@
  *
  */
 
+#include <linux/syscalls.h>
 #include <drm/drmP.h>
 #include <drm/i915_drm.h>
 #include "i915_drv.h"
@@ -600,6 +601,28 @@ static int logical_ring_alloc_seqno(struct intel_engine_cs *ring,
 	return i915_gem_get_seqno(ring->dev, &ring->outstanding_lazy_seqno);
 }
 
+static int logical_ring_write_active_seqno(struct intel_ringbuffer *ringbuf,
+					   u32 seqno)
+{
+	int ret;
+	struct intel_engine_cs *ring = ringbuf->ring;
+
+	ret = intel_logical_ring_begin(ringbuf, 4);
+	if (ret)
+		return ret;
+
+	intel_logical_ring_emit(ringbuf, MI_STORE_DWORD_INDEX);
+	intel_logical_ring_emit(ringbuf,
+				(ring->status_page.gfx_addr +
+				 (I915_GEM_ACTIVE_SEQNO_INDEX <<
+				  MI_STORE_DWORD_INDEX_SHIFT)));
+	intel_logical_ring_emit(ringbuf, seqno);
+	intel_logical_ring_emit(ringbuf, MI_NOOP);
+	intel_logical_ring_advance(ringbuf);
+
+	return 0;
+}
+
 static int execlists_move_to_gpu(struct intel_ringbuffer *ringbuf,
 				 struct list_head *vmas)
 {
@@ -662,7 +685,7 @@ int intel_execlists_submission(struct drm_device *dev, struct drm_file *file,
 	u32 instp_mask;
 	int ret;
 	u32 seqno;
-	void *handle = NULL;
+	int fd_fence_complete = -1;
 
 	instp_mode = args->flags & I915_EXEC_CONSTANTS_MASK;
 	instp_mask = I915_EXEC_CONSTANTS_MASK;
@@ -711,12 +734,6 @@ int intel_execlists_submission(struct drm_device *dev, struct drm_file *file,
 	}
 
 	seqno = ring->outstanding_lazy_seqno;
-	handle = gen8_sync_prepare_request(args, ringbuf, seqno);
-	if (handle && IS_ERR(handle)) {
-		ret = PTR_ERR(handle);
-		if (ret)
-			return ret;
-	}
 
 	ret = execlists_move_to_gpu(ringbuf, vmas);
 	if (ret)
@@ -737,18 +754,75 @@ int intel_execlists_submission(struct drm_device *dev, struct drm_file *file,
 		dev_priv->relative_constants_mode = instp_mode;
 	}
 
+#ifdef CONFIG_SYNC
+	if (args->flags & I915_EXEC_WAIT_FENCE) {
+		/* Validate the fence wait parameter but don't do the wait until
+		 * a scheduler arrives. Otherwise the entire universe stalls. */
+		int fd_fence_wait = (int) args->rsvd2;
+
+		if (fd_fence_wait < 0) {
+			DRM_ERROR("Wait fence for ring %d has invalid id %d\n",
+				  (int) ring->id, fd_fence_wait);
+		} else {
+			struct sync_fence *fence_wait;
+
+			fence_wait = sync_fence_fdget(fd_fence_wait);
+			if (fence_wait == NULL)
+				DRM_ERROR("Invalid wait fence %d\n",
+					  fd_fence_wait);
+		}
+	}
+#endif
+
+	if (args->flags & I915_EXEC_REQUEST_FENCE) {
+		/* Caller has requested a sync fence.
+		 * User interrupts will be enabled to make sure that
+		 * the timeline is signalled on completion. */
+		ret = i915_sync_create_fence(ring, seqno,
+					     &fd_fence_complete,
+					     args->flags & I915_EXEC_RING_MASK);
+		if (ret) {
+			DRM_ERROR("Fence creation failed for ring %d\n",
+				  ring->id);
+			args->rsvd2 = (__u64) -1;
+			return ret;
+		}
+
+		/* Return the fence through the rsvd2 field */
+		args->rsvd2 = (__u64) fd_fence_complete;
+	}
+
+	/* Flag this seqno as being active on the ring so the watchdog
+	 * code knows where to look if things go wrong. */
+	ret = logical_ring_write_active_seqno(ringbuf, seqno);
+	if (ret) {
+		DRM_DEBUG_DRIVER("Failed to store seqno for %d (%d)\n",
+				 ring->id, ret);
+		goto error;
+	}
+
 	ret = ring->emit_bb_start(ringbuf, exec_start, flags);
 	if (ret)
-		return ret;
+		goto error;
 
-	ret = gen8_sync_finish_request(handle, args, ringbuf);
+	/* Clear the active seqno again */
+	ret = logical_ring_write_active_seqno(ringbuf, 0);
 	if (ret)
-		i915_sync_cancel_request(handle, args, ring);
+		goto error;
 
 	i915_gem_execbuffer_move_to_active(vmas, ring);
 	i915_gem_execbuffer_retire_commands(dev, file, ring, batch_obj);
 
 	return 0;
+
+error:
+	if (fd_fence_complete != -1)
+		sys_close(fd_fence_complete);
+
+	if (args->flags & I915_EXEC_REQUEST_FENCE)
+		args->rsvd2 = (__u64) -1;
+
+	return ret;
 }
 
 void intel_logical_ring_stop(struct intel_engine_cs *ring)
diff --git a/drivers/gpu/drm/i915/intel_ringbuffer.c b/drivers/gpu/drm/i915/intel_ringbuffer.c
index d8c7c80..688a771 100644
--- a/drivers/gpu/drm/i915/intel_ringbuffer.c
+++ b/drivers/gpu/drm/i915/intel_ringbuffer.c
@@ -1716,6 +1716,26 @@ void intel_cleanup_ring_buffer(struct intel_engine_cs *ring)
 	ring->buffer = NULL;
 }
 
+/* Write a specific seqno value to the HWS page so that
+ * we can identify the cause of any hangs. */
+int i915_write_active_seqno(struct intel_engine_cs *ring, u32 seqno)
+{
+	int ret;
+
+	ret = intel_ring_begin(ring, 4);
+	if (ret)
+		return ret;
+
+	intel_ring_emit(ring, MI_STORE_DWORD_INDEX);
+	intel_ring_emit(ring, I915_GEM_ACTIVE_SEQNO_INDEX <<
+			MI_STORE_DWORD_INDEX_SHIFT);
+	intel_ring_emit(ring, seqno);
+	intel_ring_emit(ring, MI_NOOP);
+	intel_ring_advance(ring);
+
+	return 0;
+}
+
 static int intel_ring_wait_request(struct intel_engine_cs *ring, int n)
 {
 	struct intel_ringbuffer *ringbuf = ring->buffer;
diff --git a/drivers/gpu/drm/i915/intel_ringbuffer.h b/drivers/gpu/drm/i915/intel_ringbuffer.h
index bb1dbb8..8ff5986 100644
--- a/drivers/gpu/drm/i915/intel_ringbuffer.h
+++ b/drivers/gpu/drm/i915/intel_ringbuffer.h
@@ -373,6 +373,8 @@ static inline u32 intel_ring_get_tail(struct intel_ringbuffer *ringbuf)
 	return ringbuf->tail;
 }
 
+int i915_write_active_seqno(struct intel_engine_cs *ring, u32 seqno);
+
 static inline u32 intel_ring_get_seqno(struct intel_engine_cs *ring)
 {
 	BUG_ON(ring->outstanding_lazy_seqno == 0);
diff --git a/drivers/gpu/drm/i915/intel_sync.c b/drivers/gpu/drm/i915/intel_sync.c
index 687cfb3..0a2a3ad 100644
--- a/drivers/gpu/drm/i915/intel_sync.c
+++ b/drivers/gpu/drm/i915/intel_sync.c
@@ -99,7 +99,7 @@ static int i915_sync_fill_driver_data(struct sync_pt *sync_pt,
 
 static
 struct sync_pt *i915_sync_pt_create(struct i915_sync_timeline *obj,
-					u32 value, u32 cycle, u64 flags)
+				    u32 value, u32 cycle, u64 ring_mask)
 {
 	struct i915_sync_pt *pt;
 	struct intel_engine_cs *ring;
@@ -119,7 +119,7 @@ struct sync_pt *i915_sync_pt_create(struct i915_sync_timeline *obj,
 	if (pt) {
 		pt->pvt.value = value;
 		pt->pvt.cycle = cycle;
-		pt->pvt.flags = flags & I915_EXEC_RING_MASK;
+		pt->pvt.ring_mask = ring_mask;
 	} else
 		ring->irq_put(ring);
 
@@ -135,7 +135,7 @@ static struct sync_pt *i915_sync_pt_dup(struct sync_pt *sync_pt)
 		(struct i915_sync_timeline *)sync_pt->parent;
 
 	new_pt = (struct sync_pt *)i915_sync_pt_create(obj, pt->pvt.value,
-					pt->pvt.cycle, pt->pvt.flags);
+					pt->pvt.cycle, pt->pvt.ring_mask);
 	return new_pt;
 }
 
@@ -217,136 +217,24 @@ void i915_sync_reset_timelines(struct drm_i915_private *dev_priv)
 	}
 }
 
-static int i915_write_active_seqno(struct intel_engine_cs *ring, u32 seqno)
+int i915_sync_create_fence(struct intel_engine_cs *ring, u32 seqno,
+			   int *fd_out, u64 ring_mask)
 {
-	int ret;
-
-	ret = intel_ring_begin(ring, 4);
-	if (ret)
-		return ret;
-
-	intel_ring_emit(ring, MI_STORE_DWORD_INDEX);
-	intel_ring_emit(ring, I915_GEM_ACTIVE_SEQNO_INDEX <<
-			MI_STORE_DWORD_INDEX_SHIFT);
-	intel_ring_emit(ring, seqno);
-	intel_ring_emit(ring, MI_NOOP);
-	intel_ring_advance(ring);
-
-	return 0;
-}
-
-void *i915_sync_prepare_request(struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring, u32 seqno)
-{
-	int ret;
 	struct sync_pt *pt;
+	int fd = -1, err;
+	struct sync_fence *fence;
 
 	BUG_ON(!ring->timeline);
 
-	/* Write the current seqno to the HWS page so that
-	 * we can identify the cause of any hangs.
-	 */
-	ret = i915_write_active_seqno(ring, seqno);
-	if (ret) {
-		DRM_DEBUG_DRIVER("Failed to store seqno for %d (%d)\n",
-				 ring->id, ret);
-		return ERR_PTR(ret);
-	}
-
-	/* Fence was not requested, nothing more to do. */
-	if (!(args->flags & I915_EXEC_REQUEST_FENCE))
-		return NULL;
-
-	/* Caller has requested a sync fence.
-	 * User interrupts will be enabled to make sure that
-	 * the timeline is signalled on completion.
-	 */
 	pt = i915_sync_pt_create(ring->timeline, seqno,
 				 ring->timeline->pvt.cycle,
-				 args->flags);
-	if (!pt)
+				 ring_mask);
+	if (!pt) {
 		DRM_DEBUG_DRIVER("Failed to create sync point for %d/%u\n",
 					ring->id, seqno);
-
-	return (void *)pt;
-}
-
-static int gen8_write_active_seqno(struct intel_ringbuffer *ringbuf, u32 seqno)
-{
-	int ret;
-	struct intel_engine_cs *ring = ringbuf->ring;
-
-	ret = intel_logical_ring_begin(ringbuf, 4);
-	if (ret)
-		return ret;
-
-	intel_logical_ring_emit(ringbuf, MI_STORE_DWORD_INDEX);
-	intel_logical_ring_emit(ringbuf,
-				(ring->status_page.gfx_addr +
-				 (I915_GEM_ACTIVE_SEQNO_INDEX <<
-				  MI_STORE_DWORD_INDEX_SHIFT)));
-	intel_logical_ring_emit(ringbuf, seqno);
-	intel_logical_ring_emit(ringbuf, MI_NOOP);
-	intel_logical_ring_advance(ringbuf);
-
-	return 0;
-}
-
-void *gen8_sync_prepare_request(struct drm_i915_gem_execbuffer2 *args,
-				struct intel_ringbuffer *ringbuf,
-				u32 seqno)
-{
-	int ret;
-	struct sync_pt *pt;
-	struct intel_engine_cs *ring = ringbuf->ring;
-
-	BUG_ON(!ring->timeline);
-
-	/* Write the current seqno to the HWS page so that
-	 * we can identify the cause of any hangs.
-	 */
-	ret = gen8_write_active_seqno(ringbuf, seqno);
-	if (ret) {
-		DRM_DEBUG_DRIVER("Failed to store seqno for %d (%d)\n",
-				 ring->id, ret);
-		return ERR_PTR(ret);
+		return -ENOMEM;
 	}
 
-	/* Fence was not requested, nothing more to do. */
-	if (!(args->flags & I915_EXEC_REQUEST_FENCE))
-		return NULL;
-
-	/* Caller has requested a sync fence.
-	 * User interrupts will be enabled to make sure that
-	 * the timeline is signalled on completion.
-	 */
-	pt = i915_sync_pt_create(ring->timeline, seqno,
-				 ring->timeline->pvt.cycle,
-				 args->flags);
-	if (!pt)
-		DRM_DEBUG_DRIVER("Failed to create sync point for %d/%u\n",
-					ring->id, seqno);
-
-	return (void *)pt;
-}
-
-int i915_sync_finish_request(void *handle,
-				struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring)
-{
-	struct sync_pt *pt = (struct sync_pt *)handle;
-	int err;
-	int fd = -1;
-	struct sync_fence *fence;
-
-	/* Clear the active seqno. */
-	if (i915_write_active_seqno(ring, 0))
-		DRM_DEBUG_DRIVER("Failed to clear seqno for %d\n", ring->id);
-
-	/* Fence was not requested, nothing more to do. */
-	if (!pt)
-		return 0;
-
 	fd = get_unused_fd();
 	if (fd < 0) {
 		DRM_DEBUG_DRIVER("Unable to get file descriptor for fence\n");
@@ -355,86 +243,21 @@ int i915_sync_finish_request(void *handle,
 	}
 
 	fence = sync_fence_create("I915", pt);
-	if (!fence) {
-		DRM_DEBUG_DRIVER("Fence creation failed\n");
-		err = -ENOMEM;
-		goto err_fd;
-	}
-
-	sync_fence_install(fence, fd);
-
-	/* Return the fence through the rsvd2 field */
-	args->rsvd2 = (__u64)fd;
-
-	return 0;
-
-err_fd:
-	put_unused_fd(fd);
-	fd = err;
-err:
-	args->rsvd2 = (__u64)fd;
-
-	return err;
-}
-
-int gen8_sync_finish_request(void *handle,
-			     struct drm_i915_gem_execbuffer2 *args,
-			     struct intel_ringbuffer *ringbuf)
-{
-	struct sync_pt *pt = (struct sync_pt *)handle;
-	int err;
-	int fd = -1;
-	struct sync_fence *fence;
-	struct intel_engine_cs *ring = ringbuf->ring;
-
-	/* Clear the active seqno. */
-	if (gen8_write_active_seqno(ringbuf, 0))
-		DRM_DEBUG_DRIVER("Failed to clear seqno for %d\n", ring->id);
-
-	/* Fence was not requested, nothing more to do. */
-	if (!pt)
+	if (fence) {
+		sync_fence_install(fence, fd);
+		*fd_out = fd;
 		return 0;
-
-	fd = get_unused_fd();
-	if (fd < 0) {
-		DRM_DEBUG_DRIVER("Unable to get file descriptor for fence\n");
-		err = fd;
-		goto err;
-	}
-
-	fence = sync_fence_create("I915", pt);
-	if (!fence) {
-		DRM_DEBUG_DRIVER("Fence creation failed\n");
-		err = -ENOMEM;
-		goto err_fd;
 	}
 
-	sync_fence_install(fence, fd);
-
-	/* Return the fence through the rsvd2 field */
-	args->rsvd2 = (__u64)fd;
-
-	return 0;
-
-err_fd:
+	DRM_DEBUG_DRIVER("Fence creation failed\n");
+	err = -ENOMEM;
 	put_unused_fd(fd);
-	fd = err;
 err:
-	args->rsvd2 = (__u64)fd;
-
+	sync_pt_free(pt);
+	*fd_out = -1;
 	return err;
 }
 
-void i915_sync_cancel_request(void *handle,
-				struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring)
-{
-	struct sync_pt *pt = (struct sync_pt *)handle;
-
-	if (pt && !IS_ERR(pt))
-		sync_pt_free(pt);
-}
-
 void i915_sync_timeline_advance(struct intel_engine_cs *ring)
 {
 	if (ring->timeline)
diff --git a/drivers/gpu/drm/i915/intel_sync.h b/drivers/gpu/drm/i915/intel_sync.h
index 5813dbc..50b6e0a 100644
--- a/drivers/gpu/drm/i915/intel_sync.h
+++ b/drivers/gpu/drm/i915/intel_sync.h
@@ -67,20 +67,10 @@ int i915_sync_timeline_create(struct drm_device *dev,
 void i915_sync_timeline_destroy(struct intel_engine_cs *ring);
 
 void i915_sync_reset_timelines(struct drm_i915_private *dev_priv);
-void *i915_sync_prepare_request(struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring, u32 seqno);
-void *gen8_sync_prepare_request(struct drm_i915_gem_execbuffer2 *args,
-				struct intel_ringbuffer *ringbuf,
-				u32 seqno);
-int i915_sync_finish_request(void *handle,
-				struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring);
-int gen8_sync_finish_request(void *handle,
-			     struct drm_i915_gem_execbuffer2 *args,
-			     struct intel_ringbuffer *ringbuf);
-void i915_sync_cancel_request(void *handle,
-			      struct drm_i915_gem_execbuffer2 *args,
-			      struct intel_engine_cs *ring);
+
+int i915_sync_create_fence(struct intel_engine_cs *ring, u32 seqno,
+			   int *fd_out, u64 ring_mask);
+
 void i915_sync_timeline_advance(struct intel_engine_cs *ring);
 void i915_sync_hung_ring(struct intel_engine_cs *ring);
 
@@ -106,44 +96,10 @@ void i915_sync_reset_timelines(struct drm_i915_private *dev_priv)
 
 }
 
-static inline
-void *i915_sync_prepare_request(struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring, u32 seqno)
-{
-	return NULL;
-}
-
-static inline
-void *gen8_sync_prepare_request(struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring,
-				struct intel_context *ctx, u32 seqno)
-{
-	return NULL;
-}
-
-static inline
-int i915_sync_finish_request(void *handle,
-				struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring)
+static int i915_sync_create_fence(struct intel_engine_cs *ring, u32 seqno,
+				  int *fd_out)
 {
-	return 0;
-}
-
-static inline
-int gen8_sync_finish_request(void *handle,
-				struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring,
-				struct intel_context *ctx)
-{
-	return 0;
-}
-
-static inline
-void i915_sync_cancel_request(void *handle,
-				struct drm_i915_gem_execbuffer2 *args,
-				struct intel_engine_cs *ring)
-{
-
+	return 0
 }
 
 static inline
diff --git a/include/uapi/drm/i915_drm.h b/include/uapi/drm/i915_drm.h
index 6aa7957..d233b1c 100644
--- a/include/uapi/drm/i915_drm.h
+++ b/include/uapi/drm/i915_drm.h
@@ -842,7 +842,7 @@ struct drm_i915_gem_execbuffer2 {
 struct drm_i915_gem_syncpt_driver_data {
 	__u32 value;
 	__u32 cycle;
-	__u64 flags;
+	__u64 ring_mask;
 };
 
 struct drm_i915_gem_pin {
-- 
1.7.9.5

