From 8d795792af41737b4222cc1443fa540dae940572 Mon Sep 17 00:00:00 2001
From: Yuyang Du <yuyang.du@intel.com>
Date: Mon, 17 Nov 2014 19:59:36 -0500
Subject: [PATCH] sched: Implement workload consolidation in idle_balance

We do the following:

(1) Skip pulling task to the idle non-consolidated CPUs.

(2) For consolidated Idle CPU, we aggressively pull tasks from
    non-consolidated CPUs.

Change-Id: Ib29e1e45a6b89a7026321e4b24d3c4ad84da1db9
Orig-Change-Id: If2ba1a76cf6a5e17866d8ee5968b4d618f43c371
Orig-Tracked-On: https://jira01.devtools.intel.com/browse/GMINL-20603
Tracked-On: https://jira01.devtools.intel.com/browse/OAM-9774
Signed-off-by: Yuyang Du <yuyang.du@intel.com>
Signed-off-by: Srinidhi Kasagar <srinidhi.kasagar@intel.com>
---
 kernel/sched/fair.c | 19 +++++++++++++++++++
 1 file changed, 19 insertions(+)

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 3f9a10b..07e819e 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -2399,6 +2399,8 @@ static inline void dequeue_entity_load_avg(struct cfs_rq *cfs_rq,
 void update_cpu_concurrency(struct rq *rq);
 static struct sched_group *wc_find_group(struct sched_domain *sd,
 	struct task_struct *p, int this_cpu);
+static void wc_unload(struct cpumask *nonshielded, struct sched_domain *sd);
+static void wc_nonshielded_mask(struct sched_domain *sd, struct cpumask *mask);
 static int cpu_cc_capable(int cpu);
 
 /*
@@ -6396,6 +6398,22 @@ void idle_balance(int this_cpu, struct rq *this_rq)
 
 	update_blocked_averages(this_cpu);
 	rcu_read_lock();
+
+	sd = rcu_dereference(per_cpu(sd_wc, this_cpu));
+	if (sd) {
+		struct cpumask *nonshielded_cpus = __get_cpu_var(load_balance_mask);
+
+		cpumask_copy(nonshielded_cpus, cpu_active_mask);
+
+		/*
+		 * If we encounter shielded CPU here, don't do balance on them
+		 */
+		wc_nonshielded_mask(sd, nonshielded_cpus);
+		if (!cpumask_test_cpu(this_cpu, nonshielded_cpus))
+			goto unlock;
+		wc_unload(nonshielded_cpus, sd);
+	}
+
 	for_each_domain(this_cpu, sd) {
 		unsigned long interval;
 		int continue_balancing = 1;
@@ -6430,6 +6448,7 @@ void idle_balance(int this_cpu, struct rq *this_rq)
 			break;
 		}
 	}
+unlock:
 	rcu_read_unlock();
 
 	raw_spin_lock(&this_rq->lock);
-- 
1.9.1

